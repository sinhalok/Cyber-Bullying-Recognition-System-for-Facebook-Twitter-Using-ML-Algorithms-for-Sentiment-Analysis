{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     C:\\Users\\aloks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('sentiwordnet')\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Basic Packages\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# Text Preprocessing Packages\n",
    "import re\n",
    "import nltk\n",
    "# from nltk.tokenize import word_tokenize\n",
    "import tweepy \n",
    "from tweepy.auth import OAuthHandler\n",
    "from textblob import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(name):\n",
    "    #name='gandhi'\n",
    "    def initialize(): \n",
    "\n",
    "        # keys and tokens from the Twitter Dev Console \n",
    "        consumer_key = 'snseusIoIioTvEpDaBcPjUryw'\n",
    "        consumer_secret = 'cDhGVySW9xRUQSbc2o8yKMHfAxBrnIBvE1wSaWoz1PIBXspFTm'\n",
    "        access_token = '2856915038-5xVKLBpmMhX3l4uHBZfmdmIRtXGt1Q0K8yUrexR'\n",
    "        access_token_secret = 'uiHGPQZuxr9z0bsnaPMPgdMemk8oXOwUYjSLJfsT2VmCM'\n",
    "\n",
    "        # attempt authentication \n",
    "        try: \n",
    "            # create OAuthHandler object \n",
    "            auth = OAuthHandler(consumer_key, consumer_secret) \n",
    "            # set access token and secret \n",
    "            auth.set_access_token(access_token, access_token_secret) \n",
    "            # create tweepy API object to fetch tweets \n",
    "            api = tweepy.API(auth,wait_on_rate_limit=True) \n",
    "            print('Authentication Success')\n",
    "            return(api)\n",
    "\n",
    "        except Exception as e: \n",
    "            print(\"Error: Authentication Failed\")\n",
    "            print(e)\n",
    "\n",
    "\n",
    "    def get_tweets(api, query, count = 100): \n",
    "            # empty list to store parsed tweets \n",
    "            tweets = [] \n",
    "            sinceId = None\n",
    "            max_id = -1\n",
    "            tweetCount = 0\n",
    "            tweetsPerQry = 100\n",
    "\n",
    "            while tweetCount < count:\n",
    "                try:\n",
    "                    if (max_id <= 0):\n",
    "                        if (not sinceId):\n",
    "                            new_tweets = api.search(q=query, count=tweetsPerQry,lang='en')\n",
    "                        else:\n",
    "                            new_tweets = api.search(q=query, count=tweetsPerQry,\n",
    "                                                    since_id=sinceId,lang='en')\n",
    "                    else:\n",
    "                        if (not sinceId):\n",
    "                            new_tweets = api.search(q=query, count=tweetsPerQry,\n",
    "                                                    max_id=str(max_id - 1),lang='en')\n",
    "                        else:\n",
    "                            new_tweets = api.search(q=query, count=tweetsPerQry,\n",
    "                                                    max_id=str(max_id - 1),\n",
    "                                                    since_id=sinceId,lang='en')\n",
    "                    if not new_tweets:\n",
    "                        print(\"No more tweets found\")\n",
    "                        break\n",
    "\n",
    "                    for tweet in new_tweets:\n",
    "                        parsed_tweet = {} \n",
    "                        parsed_tweet['tweets'] = tweet.text\n",
    "                        parsed_tweet['date'] = tweet.created_at\n",
    "\n",
    "                        # saving sentiment of tweet \n",
    "                        parsed_tweet['cleaned_tweets'],parsed_tweet['sentiment_score'],parsed_tweet['sentiment'] = get_sentiment(tweet.text)\n",
    "                        #parsed_tweet['sentiments'] = [tag_sentiment(tweet.text)]\n",
    "                        # appending parsed tweet to tweets list \n",
    "                        if tweet.retweet_count > 0: \n",
    "                            # if tweet has retweets, ensure that it is appended only once \n",
    "                            if parsed_tweet not in tweets: \n",
    "                                tweets.append(parsed_tweet) \n",
    "                        else: \n",
    "                            tweets.append(parsed_tweet) \n",
    "\n",
    "                    tweetCount += len(new_tweets)\n",
    "                    #print(\"Downloaded {0} tweets\".format(tweetCount))\n",
    "                    max_id = new_tweets[-1].id\n",
    "                   # print(max_id)\n",
    "                   # print(new_tweets[-1])\n",
    "                    return tweets\n",
    "                except tweepy.TweepError as e:\n",
    "                    print(\"Tweepy error : \" + str(e))\n",
    "\n",
    "    api_initialization = initialize()\n",
    "    \n",
    "    def clean_tweet(tweets): \n",
    "        ''' \n",
    "        Utility function to clean tweet text by removing links, special characters \n",
    "        using simple regex statements. \n",
    "        '''\n",
    "        #print(tweets)\n",
    "        return(' '.join(re.sub(\"([,\\.():;!$%^&*\\d])|([^0-9A-Za-z \\t])\", \" \", tweets).split())) \n",
    "\n",
    "    def penn_to_wn(tag):\n",
    "        if tag.startswith('J'):\n",
    "            return wn.ADJ\n",
    "        elif tag.startswith('N'):\n",
    "            return wn.NOUN\n",
    "        elif tag.startswith('R'):\n",
    "            return wn.ADV\n",
    "        elif tag.startswith('V'):\n",
    "            return wn.VERB\n",
    "        return None\n",
    "\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def get_sentiment(text):\n",
    "        \"\"\" returns list of pos neg and objective score. But returns empty list if not present in senti wordnet. \"\"\"\n",
    "        cleaned_tweets = preprocess_tweet(text)\n",
    "        tagged = nltk.pos_tag(word_tokenize(cleaned_tweets))\n",
    "        sentiment_score = 0.0\n",
    "        tokens_count = 0\n",
    "        sentiment = []\n",
    "        for word, tag in tagged:\n",
    "            wn_tag = penn_to_wn(tag)\n",
    "            if wn_tag not in (wn.NOUN, wn.ADJ, wn.ADV):\n",
    "                continue\n",
    "\n",
    "            lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
    "            if not lemma:\n",
    "                continue\n",
    "\n",
    "            synsets = wn.synsets(word, pos=wn_tag)\n",
    "            if not synsets:\n",
    "                continue\n",
    "\n",
    "        # Take the first sense, the most common\n",
    "            synset = synsets[0]\n",
    "    #         print(synset)\n",
    "    #         print(synset.name())\n",
    "            swn_synset = swn.senti_synset(synset.name())\n",
    "    #         print(swn_synset)\n",
    "            sentiment_score += swn_synset.pos_score() - swn_synset.neg_score()\n",
    "        \n",
    "            tokens_count += 1\n",
    "        if not tokens_count:\n",
    "            sentiment.append('neutral')\n",
    " \n",
    "    # sum greater than 0 => positive sentiment\n",
    "        if sentiment_score >= 0:\n",
    "            sentiment.append('positive')\n",
    "        else:\n",
    "            sentiment.append('negative')\n",
    "        # negative sentiment\n",
    "\n",
    "\n",
    "        return cleaned_tweets,sentiment_score, sentiment.pop()\n",
    "\n",
    "    contractions = {\n",
    "\"ain't\": \"is not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he'll've\": \"he he will have\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"I'd\": \"I would\",\n",
    "\"I'd've\": \"I would have\",\n",
    "\"I'll\": \"I will\",\n",
    "\"I'll've\": \"I will have\",\n",
    "\"I'm\": \"I am\",\n",
    "\"I've\": \"I have\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'd've\": \"i would have\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'll've\": \"i will have\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it'll've\": \"it will have\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she'll've\": \"she will have\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they'll've\": \"they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what'll've\": \"what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who'll've\": \"who will have\",\n",
    "\"who's\": \"who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you'll've\": \"you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}\n",
    "\n",
    "    def expand_contractions(text):\n",
    "        for word in text.split():\n",
    "            if word.lower() in contractions:\n",
    "                text = text.replace(word, contractions[word.lower()])\n",
    "        return text\n",
    "\n",
    "    def preprocess_word(word):\n",
    "        # Remove punctuation\n",
    "        word = word.strip('\"?!,.():;')\n",
    "        # Convert more than 2 letter repetitions to 2 letter\n",
    "        # funnnnny --> funny\n",
    "        word = re.sub(r'(.)\\1+', r'\\1\\1', word)\n",
    "        # Remove - & '\n",
    "        word = re.sub(r'(-)', '', word)\n",
    "        return word\n",
    "\n",
    "    def is_valid_word(word):\n",
    "        # Check if word begins with an alphabet\n",
    "        return (re.search(r'^[a-zA-Z][a-z0-9A-Z\\._]*$', word) is not None)\n",
    "\n",
    "    def handle_emojis(tweet):\n",
    "        # Smile -- :), : ), :-), (:, ( :, (-:, :')\n",
    "        tweet = re.sub(r'(:\\s?\\)|:-\\)|\\(\\s?:|\\(-:|:\\'\\))', ' EMO_POS ', tweet)\n",
    "        # Laugh -- :D, : D, :-D, xD, x-D, XD, X-D\n",
    "        tweet = re.sub(r'(:\\s?D|:-D|x-?D|X-?D)', ' EMO_POS ', tweet)\n",
    "        # Love -- <3, :*\n",
    "        tweet = re.sub(r'(<3|:\\*)', ' EMO_POS ', tweet)\n",
    "        # Wink -- ;-), ;), ;-D, ;D, (;,  (-;\n",
    "        tweet = re.sub(r'(;-?\\)|;-?D|\\(-?;)', ' EMO_POS ', tweet)\n",
    "        # Sad -- :-(, : (, :(, ):, )-:\n",
    "        tweet = re.sub(r'(:\\s?\\(|:-\\(|\\)\\s?:|\\)-:)', ' EMO_NEG ', tweet)\n",
    "        # Cry -- :,(, :'(, :\"(\n",
    "        tweet = re.sub(r'(:,\\(|:\\'\\(|:\"\\()', ' EMO_NEG ', tweet)\n",
    "        return tweet\n",
    "    from nltk import WordNetLemmatizer\n",
    "\n",
    "    def preprocess_tweet(tweet):\n",
    "        processed_tweet = []\n",
    "        # Convert to lower case\n",
    "        tweet = tweet.lower()\n",
    "        tweet = expand_contractions(re.sub('’', \"'\", tweet))\n",
    "        # Replaces URLs with the word URL\n",
    "        tweet = re.sub(r'((www\\.[\\S]+)|(https?://[\\S]+))', ' URL ', tweet)\n",
    "        # Replace @handle with the word USER_MENTION\n",
    "        tweet = re.sub(r'@[\\S]+', r' ', tweet)\n",
    "        # Replaces #hashtag with hashtag\n",
    "        tweet = re.sub(r'#(\\S+)', r' \\1 ', tweet)\n",
    "        # Remove RT (retweet)\n",
    "        tweet = re.sub(r'\\brt\\b', '', tweet)\n",
    "        # Replace 2+ dots with space\n",
    "        tweet = re.sub(r'\\.{2,}', ' ', tweet)\n",
    "        # Strip space, \" and ' from tweet\n",
    "        #tweet = tweet.strip(' \"\\'')\n",
    "        # Replace emojis with either EMO_POS or EMO_NEG\n",
    "        tweet = handle_emojis(tweet)\n",
    "        # Replace multiple spaces with a single space\n",
    "        tweet = re.sub(r'\\s+', ' ', tweet)\n",
    "        tweet = re.sub(r'(\\[|\\])',' ', tweet)\n",
    "        \n",
    "        words = tweet.split()\n",
    "\n",
    "        for word in words:\n",
    "            word = preprocess_word(word)\n",
    "            if is_valid_word(word):\n",
    "                #if use_stemmer:\n",
    "                word = str(WordNetLemmatizer().lemmatize(word))\n",
    "                processed_tweet.append(word)\n",
    "\n",
    "        return ' '.join(processed_tweet)\n",
    "\n",
    "    global retreived_tweets\n",
    "    retreived_tweets = get_tweets(api=api_initialization,query=name, count = 100)\n",
    "\n",
    "        \n",
    "    return retreived_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication Success\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    get_data('OnePlus 8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>date</th>\n",
       "      <th>cleaned_tweets</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OnePlus 8, OnePlus 8 Pro, and OnePlus 8T Getti...</td>\n",
       "      <td>2021-04-20 11:29:35</td>\n",
       "      <td>oneplus oneplus pro and oneplus getting march ...</td>\n",
       "      <td>0.750</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OnePlus 8, OnePlus 8 Pro, and OnePlus 8T Getti...</td>\n",
       "      <td>2021-04-20 11:29:34</td>\n",
       "      <td>oneplus oneplus pro and oneplus getting march ...</td>\n",
       "      <td>0.750</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @chr_engen: Oneplus 8 pro\\n\\nBig tnx to:\\n\\...</td>\n",
       "      <td>2021-04-20 11:25:06</td>\n",
       "      <td>oneplus pro big tnx to setup by template by wa...</td>\n",
       "      <td>0.250</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#NJJEX Cell Phone Holster for LG Stylo 6 5 4 K...</td>\n",
       "      <td>2021-04-20 11:24:04</td>\n",
       "      <td>njjex cell phone holster for lg stylo k92 k51 ...</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#NJJEX Cell Phone Holster for LG Stylo 6 5 4 K...</td>\n",
       "      <td>2021-04-20 11:02:03</td>\n",
       "      <td>njjex cell phone holster for lg stylo k92 k51 ...</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>RT @Android: #Android11 gives you new device c...</td>\n",
       "      <td>2021-04-19 20:44:02</td>\n",
       "      <td>android11 give you new device control privacy ...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>RT @Android: #Android11 gives you new device c...</td>\n",
       "      <td>2021-04-19 20:43:12</td>\n",
       "      <td>android11 give you new device control privacy ...</td>\n",
       "      <td>1.000</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>#Android11 gives you new device controls, priv...</td>\n",
       "      <td>2021-04-19 20:42:55</td>\n",
       "      <td>android11 give you new device control privacy ...</td>\n",
       "      <td>0.875</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Should you buy the OnePlus 8 Pro or OnePlus 8 ...</td>\n",
       "      <td>2021-04-19 20:30:01</td>\n",
       "      <td>should you buy the oneplus pro or oneplus in URL</td>\n",
       "      <td>0.000</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>@oneplus Even I use 8 GB RAM in my PC .. 😐</td>\n",
       "      <td>2021-04-19 20:24:34</td>\n",
       "      <td>even i use gb ram in my pc</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweets                date  \\\n",
       "0   OnePlus 8, OnePlus 8 Pro, and OnePlus 8T Getti... 2021-04-20 11:29:35   \n",
       "1   OnePlus 8, OnePlus 8 Pro, and OnePlus 8T Getti... 2021-04-20 11:29:34   \n",
       "2   RT @chr_engen: Oneplus 8 pro\\n\\nBig tnx to:\\n\\... 2021-04-20 11:25:06   \n",
       "3   #NJJEX Cell Phone Holster for LG Stylo 6 5 4 K... 2021-04-20 11:24:04   \n",
       "4   #NJJEX Cell Phone Holster for LG Stylo 6 5 4 K... 2021-04-20 11:02:03   \n",
       "..                                                ...                 ...   \n",
       "94  RT @Android: #Android11 gives you new device c... 2021-04-19 20:44:02   \n",
       "95  RT @Android: #Android11 gives you new device c... 2021-04-19 20:43:12   \n",
       "96  #Android11 gives you new device controls, priv... 2021-04-19 20:42:55   \n",
       "97  Should you buy the OnePlus 8 Pro or OnePlus 8 ... 2021-04-19 20:30:01   \n",
       "98         @oneplus Even I use 8 GB RAM in my PC .. 😐 2021-04-19 20:24:34   \n",
       "\n",
       "                                       cleaned_tweets  sentiment_score  \\\n",
       "0   oneplus oneplus pro and oneplus getting march ...            0.750   \n",
       "1   oneplus oneplus pro and oneplus getting march ...            0.750   \n",
       "2   oneplus pro big tnx to setup by template by wa...            0.250   \n",
       "3   njjex cell phone holster for lg stylo k92 k51 ...           -0.125   \n",
       "4   njjex cell phone holster for lg stylo k92 k51 ...           -0.125   \n",
       "..                                                ...              ...   \n",
       "94  android11 give you new device control privacy ...            1.000   \n",
       "95  android11 give you new device control privacy ...            1.000   \n",
       "96  android11 give you new device control privacy ...            0.875   \n",
       "97   should you buy the oneplus pro or oneplus in URL            0.000   \n",
       "98                         even i use gb ram in my pc           -0.125   \n",
       "\n",
       "   sentiment  \n",
       "0   positive  \n",
       "1   positive  \n",
       "2   positive  \n",
       "3   negative  \n",
       "4   negative  \n",
       "..       ...  \n",
       "94  positive  \n",
       "95  positive  \n",
       "96  positive  \n",
       "97  positive  \n",
       "98  negative  \n",
       "\n",
       "[99 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(retreived_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
